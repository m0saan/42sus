{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "pl.Config.set_tbl_hide_dataframe_shape(True)\n",
    "pl.Config.set_fmt_str_lengths(60)\n",
    "pl.Config.set_tbl_rows(25)\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import load_dataset\n",
    "\n",
    "bikeshop_dataset = load_dataset('m0saan/bikeshop')\n",
    "\n",
    "\n",
    "df = bikeshop_dataset['train'].to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into input (text) and labels\n",
    "X = df[\"text\"]\n",
    "y = df[\"intent\"]\n",
    "\n",
    "# Create a label encoder to convert labels to numerical values\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Create a custom dataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, X, y, max_len):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.X.iloc[idx]\n",
    "        label = self.y[idx]\n",
    "\n",
    "        # Tokenize the text\n",
    "        tokens = text.split()\n",
    "\n",
    "        # Pad the tokens to the maximum length\n",
    "        tokens = tokens[:self.max_len]\n",
    "        tokens += [\"<PAD>\"] * (self.max_len - len(tokens))\n",
    "\n",
    "        # Convert tokens to numerical values\n",
    "        tokens = [dataset_vocab.get(token, dataset_vocab[\"<UNK>\"]) for token in tokens]\n",
    "\n",
    "        # Convert to tensor\n",
    "        tokens = torch.tensor(tokens)\n",
    "\n",
    "        return tokens, torch.tensor(label)\n",
    "\n",
    "# Create a vocabulary\n",
    "dataset_vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "for text in X:\n",
    "    tokens = text.split()\n",
    "    for token in tokens:\n",
    "        if token not in dataset_vocab:\n",
    "            dataset_vocab[token] = len(dataset_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vocabulary size:\", len(dataset_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset and data loader\n",
    "max_len = 32\n",
    "dataset = TextDataset(X, y_encoded, max_len)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(iter(train_loader))\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "def train(\n",
    "    dl_loader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: torch.nn.Module,\n",
    "    model: torch.nn.Module,\n",
    "    ):\n",
    "    \n",
    "    \"\"\" Train the model on the training dataset \"\"\"\n",
    "    \n",
    "    total_loss, total_acc = 0, 0\n",
    "    \n",
    "    model.train()\n",
    "    for text, label in dl_loader:\n",
    "        text = text.to(device)\n",
    "        label = label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(text)\n",
    "        loss = criterion(preds, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, preds = torch.max(preds, 1)\n",
    "        total_loss += loss.item() * label.size(0)\n",
    "        total_acc += (preds  == label).float().sum().item()\n",
    "    return total_loss / len(dl_loader.dataset), total_acc / len(dl_loader.dataset)\n",
    "\n",
    "def evaluate(\n",
    "    dl_loader: torch.utils.data.DataLoader,\n",
    "    criterion: torch.nn.Module,\n",
    "    model: torch.nn.Module,\n",
    "    ):\n",
    "    \n",
    "    \"\"\" Evaluate the model on the validation or test set \"\"\"\n",
    "    \n",
    "    total_loss, total_acc = 0, 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for text, label in dl_loader:\n",
    "            preds = model(text)\n",
    "            loss = criterion(preds, label)\n",
    "            _, preds = torch.max(preds, 1)\n",
    "            total_acc += (preds == label).float().sum().item()\n",
    "            total_loss += loss.item() * label.size(0)\n",
    "        return total_loss / len(dl_loader.dataset), total_acc / len(dl_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class CNNConfig:\n",
    "    \n",
    "    vocab_size: int = len(dataset_vocab)\n",
    "    embed_dim: int = 100\n",
    "    lstm_hidden_dim: int = 100\n",
    "    fc_hidden_dim: int = 32\n",
    "    output_dim: int = 9\n",
    "    dropout: float = 0.5\n",
    "\n",
    "    num_filters: int = 100\n",
    "    num_channels: list = field(default_factory=lambda: [100, 100, 100])\n",
    "    kernel_sizes: list = field(default_factory=lambda: [3, 4, 5]) # Use default_factory for mutable defaults\n",
    "    \n",
    "    \n",
    "config = CNNConfig()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def load_glove_embeddings(glove_path, word_to_index, embed_dim):\n",
    "    embeddings_index = {}\n",
    "    with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    embedding_matrix = np.zeros((len(word_to_index), embed_dim))\n",
    "    for word, i in word_to_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return torch.tensor(embedding_matrix, dtype=torch.float32)\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, config: CNNConfig, glove_embeddings, **kwargs):\n",
    "        super(CNNModel, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(config.vocab_size, config.embed_dim)\n",
    "        \n",
    "        # The embedding layer not to be trained\n",
    "        self.constant_embedding = nn.Embedding.from_pretrained(glove_embeddings, freeze=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.decoder = nn.Linear(sum(config.num_channels), 2)\n",
    "        # The max-over-time pooling layer has no parameters, so this instance\n",
    "        # can be shared\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.relu = nn.ReLU()\n",
    "        # Create multiple one-dimensional convolutional layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        for c, k in zip(config.num_channels, config.kernel_sizes):\n",
    "            self.convs.append(nn.Conv1d(2 * config.embed_dim, c, k))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Concatenate two embedding layer outputs with shape (batch size, no.\n",
    "        # of tokens, token vector dimension) along vectors\n",
    "        embeddings = torch.cat((\n",
    "            self.embedding(inputs), self.constant_embedding(inputs)), dim=2)\n",
    "        # Per the input format of one-dimensional convolutional layers,\n",
    "        # rearrange the tensor so that the second dimension stores channels\n",
    "        embeddings = embeddings.permute(0, 2, 1)\n",
    "        # For each one-dimensional convolutional layer, after max-over-time\n",
    "        # pooling, a tensor of shape (batch size, no. of channels, 1) is\n",
    "        # obtained. Remove the last dimension and concatenate along channels\n",
    "        encoding = torch.cat([\n",
    "            torch.squeeze(self.relu(self.pool(conv(embeddings))), dim=-1)\n",
    "            for conv in self.convs], dim=1)\n",
    "        outputs = self.decoder(self.dropout(encoding))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embeddings = load_glove_embeddings('../glove/glove.6B.100d.txt', dataset_vocab, config.embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CNNModel(config, glove_embeddings)\n",
    "\n",
    "def init_weights(module):\n",
    "    if type(module) in (nn.Linear, nn.Conv1d):\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "\n",
    "net.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps')\n",
    "cnn_model = CNNModel(config, glove_embeddings).to(device)\n",
    "print(cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs = 0.001, 25\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(train_loader, optimizer, criteria, cnn_model)\n",
    "    # valid_loss, valid_acc = evaluate(valid_dataloader, criteria, cnn_model)\n",
    "    print(f'Epoch {epoch}  train loss: {train_loss:.4f} train accuracy: {train_acc:.4f}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
