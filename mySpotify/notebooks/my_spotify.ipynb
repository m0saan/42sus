{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mxm_dataset_path = 'data/mxm_dataset_train.txt'\n",
    "merged_songs_path = 'data/songs.csv'\n",
    "\n",
    "\n",
    "if not Path('data/songs.csv').exists():\n",
    "    print('Merging songs...')\n",
    "    triplet_columns = ['user_id', 'song_id', 'play_count']\n",
    "    track_columns = ['track_id', 'song_id', 'artist', 'title']\n",
    "    \n",
    "    triplet_df = pl.read_csv('data/train_triplets.txt', separator='\\t', new_columns=triplet_columns, use_pyarrow=True)\n",
    "    unique_tracks_df = pl.read_csv('data/p02_unique_tracks.csv', new_columns=track_columns)\n",
    "    triplet_df = triplet_df.group_by('song_id').agg(pl.sum('play_count').alias('play_count')).sort('play_count', descending=True)\n",
    "    mergerd_songs = triplet_df.join(unique_tracks_df, on='song_id', how='left').select('track_id', 'artist', 'title', 'play_count')\n",
    "    mergerd_songs.write_csv('data/songs.csv')\n",
    "else:\n",
    "    print('Reading songs...')\n",
    "    mergerd_songs = pl.read_csv(merged_songs_path, use_pyarrow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergerd_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MXMDataLoader:\n",
    "    def __init__(self, dataset_path_mxm, mergerd_songs):\n",
    "        self.dataset_path = dataset_path_mxm\n",
    "        self.songs = mergerd_songs\n",
    "        \n",
    "    def load(self):\n",
    "        top_words = []\n",
    "        filtered_tracks = []\n",
    "\n",
    "        with open(self.dataset_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                if line.startswith('#') or line.strip() == '':\n",
    "                    continue\n",
    "                elif line.startswith('%'):\n",
    "                    top_words = line[1:].strip().split(',')\n",
    "                else:\n",
    "                    elements = line.strip().split(',')\n",
    "                    track_id = elements[0]\n",
    "                    word_counts = {int(count.split(':')[0]) - 1: int(count.split(':')[1]) for count in elements[2:]}\n",
    "                    filtered_tracks.append((track_id, word_counts))\n",
    "        self.top_words = top_words\n",
    "        self.filtered_tracks = filtered_tracks\n",
    "        \n",
    "    def get_song_lyrics(self, track_id):\n",
    "        def get_words(top_words, word_counts):\n",
    "            return {top_words[index]:count for index, count in word_counts.items()}\n",
    "            \n",
    "        \n",
    "        for track in self.filtered_tracks:\n",
    "            if track[0] == track_id:\n",
    "                return get_words(self.top_words, track[1])\n",
    "        raise ValueError(f\"Track ID '{track_id}' not found in the dataset.\")\n",
    "    \n",
    "    def get_sorted_tracks_by_keyword(self, keyword, threshold):\n",
    "        \n",
    "        try:\n",
    "            keyword_index = self.top_words.index(keyword)\n",
    "        except ValueError:\n",
    "            print(f\"Keyword '{keyword}' not found in the dataset.\")\n",
    "            return\n",
    "            \n",
    "        filtered_tracks = []\n",
    "        for idx, (track_id, word_counts) in enumerate(self.filtered_tracks): \n",
    "            keyword_count = word_counts.get(keyword_index, 0)\n",
    "            if keyword_count >= threshold:\n",
    "                row_df = self.songs.filter(pl.col('track_id') == track_id)\n",
    "                if len(row_df) > 0:\n",
    "                    _ , artist, title, play_count = row_df[0].row(0)\n",
    "                    filtered_tracks.append((idx, track_id, artist, title, play_count, keyword_count))\n",
    "        print(\"Done ✅ filtering tracks by keyword.\")    \n",
    "        filtered_tracks_df = pl.DataFrame(filtered_tracks, schema=['index_number', 'track_id' ,'artist', 'title', 'play_count', 'keyword_count']).sort('play_count', descending=True).head(50)\n",
    "        return filtered_tracks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mxm_loader = MXMDataLoader(mxm_dataset_path, mergerd_songs)\n",
    "mxm_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try ‘love’ as the keyword and look through the lyrics of 3 random tracks given in the list of recommendations – do they have ‘love’ in the lyrics?\n",
    "tracks = mxm_loader.get_sorted_tracks_by_keyword('life', 6)\n",
    "tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mxm_loader.get_song_lyrics('TRJRECT12903CBADA3')['love']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "idx = random.randint(0, len(tracks) - 1)\n",
    "track_id = 'TROHFJK12903CC4BCE'\n",
    "print(f\"Track ID: {track_id}\")\n",
    "print(f\"Lyrics: {mxm_loader.get_song_lyrics(track_id)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If an incorrect keyword is given, the exception is handled\n",
    "incorrect_keyword_tracks = mxm_loader.get_sorted_tracks_by_keyword('incorrect_keyword', 6)\n",
    "incorrect_keyword_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "model_name = 'glove-wiki-gigaword-300'\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    vec_love = wv['love']\n",
    "except KeyError:\n",
    "    print(\"The word 'love' does not appear in this model\")\n",
    "vec_love"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MXMDataLoaderW2V:\n",
    "    def __init__(self, dataset_path_mxm, mergerd_songs, word_vectors):\n",
    "        self.dataset_path = dataset_path_mxm\n",
    "        self.songs = mergerd_songs\n",
    "        self.word_vectors = word_vectors\n",
    "        self.top_words = []\n",
    "        self.filtered_tracks = []\n",
    "\n",
    "    def load(self):\n",
    "        with open(self.dataset_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                if line.startswith('#') or line.strip() == '':\n",
    "                    continue\n",
    "                elif line.startswith('%'):\n",
    "                    self.top_words = line[1:].strip().split(',')\n",
    "                else:\n",
    "                    elements = line.strip().split(',')\n",
    "                    track_id = elements[0]\n",
    "                    word_counts = {int(count.split(':')[0]) - 1 : int(count.split(':')[1]) for count in elements[2:]}\n",
    "                    self.filtered_tracks.append((track_id, word_counts))\n",
    "\n",
    "    def get_similar_keywords(self, keyword, top_n=5):\n",
    "        \"\"\"Get top_n similar words to the given keyword.\"\"\"\n",
    "        try:\n",
    "            similar_words = self.word_vectors.most_similar(positive=[keyword], topn=top_n)\n",
    "            return [keyword] + [word for word, _ in similar_words]  # Include the keyword itself\n",
    "        except KeyError:\n",
    "            print(f\"Keyword '{keyword}' not found in the word2vec model.\")\n",
    "            return [keyword]\n",
    "\n",
    "    def get_sorted_tracks_by_keyword(self, keyword, threshold, max_tracks=50):\n",
    "        similar_keywords = self.get_similar_keywords(keyword)\n",
    "        print(f\"Similar keywords to '{keyword}': {similar_keywords}\")\n",
    "        similar_keyword_indices = [self.top_words.index(word) for word in similar_keywords if word in self.top_words]\n",
    "\n",
    "        filtered_tracks = []\n",
    "        for track_id, word_counts in self.filtered_tracks:\n",
    "            total_count = sum(word_counts.get(idx, 0) for idx in similar_keyword_indices[:5])\n",
    "            if total_count >= threshold:\n",
    "                row_df = self.songs.filter(pl.col('track_id') == track_id)\n",
    "                if len(row_df) > 0:\n",
    "                    _ , artist, title, play_count = row_df[0].row(0)\n",
    "                    filtered_tracks.append((idx, track_id, artist, title, play_count, total_count))\n",
    "        print(\"Done ✅ filtering tracks by keyword.\")    \n",
    "        filtered_tracks_df = pl.DataFrame(filtered_tracks, schema=['index_number', 'track_id' ,'artist', 'title', 'play_count', 'keyword_count']).sort('play_count', descending=True).head(50)\n",
    "                \n",
    "        return filtered_tracks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try ‘love’ as the keyword and look through the lyrics of 3 random tracks given in the list of recommendations – do they have ‘love’ in the lyrics?\n",
    "mxm_loader = MXMDataLoaderW2V(mxm_dataset_path, mergerd_songs, wv)\n",
    "mxm_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = mxm_loader.get_sorted_tracks_by_keyword('happy', 6, max_tracks=50)\n",
    "print(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
