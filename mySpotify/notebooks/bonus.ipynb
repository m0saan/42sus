{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "from colorama import Fore, Style, init\n",
    "import warnings\n",
    "import argparse\n",
    "\n",
    "# filter warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up basic configuration for logging\n",
    "logging.basicConfig(level=logging.INFO, format=f'{Fore.GREEN}%(asctime)s - %(levelname)s - %(message)s{Style.RESET_ALL}')\n",
    "\n",
    "# Initialize colorama\n",
    "init(autoreset=True)\n",
    "\n",
    "global_path = '../data'\n",
    "triplet_path = f\"{global_path}/train_triplets.txt\"\n",
    "unique_tracks_path = f\"{global_path}/p02_unique_tracks.txt\"\n",
    "genre_path = f\"{global_path}/p02_msd_tagtraum_cd2.cls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(triplet_path, unique_tracks_path):\n",
    "    logging.info('Loading data...')\n",
    "\n",
    "\n",
    "    triplet_columns = ['user_id', 'song_id', 'play_count']\n",
    "    track_columns = ['track_id', 'song_id', 'artist', 'title']\n",
    "\n",
    "    triplet_df = pl.read_csv(triplet_path, separator='\\t', new_columns=triplet_columns, use_pyarrow=True)\n",
    "    unique_tracks_df = pl.read_csv(unique_tracks_path, new_columns=track_columns, use_pyarrow=True)\n",
    "\n",
    "    logging.info('Data loaded successfully.')\n",
    "\n",
    "    logging.info('Merging songs...')\n",
    "\n",
    "    triplet_df = triplet_df.filter(pl.col('play_count') > 1)\n",
    "    songs = pd.merge(triplet_df.to_pandas(), unique_tracks_df.to_pandas(), on='song_id', how='left')\n",
    "    songs['song'] = songs['title']+' - ' + songs['artist']\n",
    "    songs = songs[['user_id', 'song_id', 'track_id', 'song', 'play_count']]\n",
    "\n",
    "    songs['user_idx'] = pd.factorize(songs['user_id'])[0]\n",
    "    songs['song_idx'] = pd.factorize(songs['song_id'])[0]\n",
    "\n",
    "    logging.info('Songs merged successfully.')\n",
    "\n",
    "    del triplet_df, unique_tracks_df\n",
    "\n",
    "    # save the data\n",
    "    # songs.to_csv('data/songs.csv', index=False)\n",
    "\n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = load_data(triplet_path, unique_tracks_path)\n",
    "X = songs[['user_idx', 'song_idx', 'song', 'play_count']]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_songs_df = X[['song_idx', 'song']].drop_duplicates(subset='song_idx')\n",
    "unique_songs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save two csv files, ratings.csv and songs.csv\n",
    "unique_songs_df.to_csv(f\"{global_path}/songs.csv\", index=False)\n",
    "songs[['user_idx', 'song_idx', 'play_count']].to_csv(f\"{global_path}/ratings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ratings = X.groupby('song_idx')['play_count'].count()\n",
    "mean_rating = X.groupby('song_idx')['play_count'].mean()\n",
    "sum_ratings = X.groupby('song_idx')['play_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_songs_df['num_ratings'] = unique_songs_df['song_idx'].map(num_ratings)\n",
    "unique_songs_df['mean_rating'] = unique_songs_df['song_idx'].map(mean_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "damping_factor = 10\n",
    "global_mean_rating = X['play_count'].mean()\n",
    "\n",
    "global_mean_rating, damping_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "damped_numerator = sum_ratings + damping_factor * global_mean_rating\n",
    "damped_denominator = num_ratings + damping_factor\n",
    "damped_mean_rating = damped_numerator / damped_denominator\n",
    "unique_songs_df['damped_mean_rating'] = unique_songs_df['song_idx'].map(damped_mean_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_songs_df.sort_values(by='num_ratings', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_songs_df.sort_values(by='mean_rating', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_songs_df.sort_values(by='damped_mean_rating', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LLMs to recommend songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data & data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(triplet_path, unique_tracks_path, genre_path):\n",
    "    logging.info('Loading data...')\n",
    "    triplet_columns = ['user_id', 'song_id', 'play_count']\n",
    "    track_columns = ['track_id', 'song_id', 'artist', 'title']\n",
    "    genre_column_names = ['track_id', 'majority_genre', 'minority_genre']\n",
    "\n",
    "    triplet_df = pl.read_csv(triplet_path, separator='\\t', new_columns=triplet_columns, use_pyarrow=True)\n",
    "    unique_tracks_df = pl.from_pandas(pd.read_csv(unique_tracks_path, names=track_columns, sep=\"<SEP>\", engine='python'))\n",
    "    genre_df = pl.from_pandas(pd.read_csv(genre_path, sep='\\t', comment='#', names=genre_column_names))\n",
    "\n",
    "    logging.info('Data loaded successfully.')\n",
    "    return triplet_df, unique_tracks_df, genre_df.drop(columns=['minority_genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_df, unique_tracks_df, genre_df = load_data(triplet_path, unique_tracks_path, genre_path)\n",
    "# songs = pd.read_csv(f\"{global_path}/songs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_play_counts = triplet_df.group_by('song_id').agg(pl.sum('play_count').alias('play_count'))\n",
    "song_play_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tracks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = song_play_counts.join(unique_tracks_df, on='song_id')\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = o.join(genre_df, on='track_id')\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming triplet_df, unique_tracks_df, and genre_df are already defined Polars DataFrames\n",
    "# Merge triplet_df with unique_tracks_df\n",
    "songs_df = triplet_df.join(\n",
    "    unique_tracks_df,\n",
    "    on=\"song_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "songs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge songs_df with genre_df\n",
    "full_songs_df = songs_df.join(\n",
    "    genre_df,\n",
    "    on=\"track_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "full_songs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_songs_df.write_csv(f\"{global_path}/full_songs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lyrics_file(file_path):\n",
    "    lyrics_dataset = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "\n",
    "        for line in file:\n",
    "            if line.startswith(\"#\") or not line.strip():\n",
    "                continue\n",
    "            elif line.startswith('%'):\n",
    "                    word_list = line[1:].strip().split(',')\n",
    "            else:\n",
    "                parts = line.split(\",\")\n",
    "                track_id = parts[0]\n",
    "                word_counts = parts[2:]\n",
    "\n",
    "                lyrics = []\n",
    "                for wc in word_counts:\n",
    "                    idx, count = map(int, wc.split(\":\"))\n",
    "                    lyrics.extend([word_list[idx - 1]])  # Word index is 1-based\n",
    "\n",
    "                lyrics_text = ' '.join(lyrics)\n",
    "                lyrics_dataset.append((track_id, lyrics_text))\n",
    "\n",
    "    return pl.DataFrame(lyrics_dataset, schema=['track_id', 'lyrics'])\n",
    "\n",
    "# Usage example:\n",
    "file_path = '../data/mxm_dataset_train.txt'\n",
    "lyrics_df = read_lyrics_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_songs_df = pl.read_csv(f\"{global_path}/full_songs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_songs_df = full_songs_df.join(\n",
    "    lyrics_df,\n",
    "    on=\"track_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "full_songs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = o.join(lyrics_df, on='track_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.write_csv(f\"{global_path}/llm_RecSys_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine title, synopsis, and Genre\n",
    "o = o.to_pandas()\n",
    "o['combined_info'] = o.apply(lambda row: f\"Song ID: {row['song_id']}\\n Artist : {row['artist']}\\n Title : {row['title']}\\n Lyrics: {row['lyrics']}.\\n Genres: {row['majority_genre']}\", axis=1)\n",
    "print(o['combined_info'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o[['combined_info']].to_csv(f\"{global_path}/llm_RecSys_dataset_updated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.combined_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the LLM recommender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.llms import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path=f\"{global_path}/llm_RecSys_dataset_updated.csv\")\n",
    "data = loader.load()\n",
    "\n",
    "#data transformers\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "#Vector DB\n",
    "docsearch = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I'm looking for a song similar by rapper like Eminem, 50 Cent and Snopp Dog. What could you suggest to me?\"\n",
    "docs = docsearch.similarity_search(query, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\", openai_api_key=api_key)\n",
    "qa = RetrievalQA.from_chain_type(llm,\n",
    "                                 chain_type=\"stuff\", \n",
    "                                 retriever=docsearch.as_retriever(), \n",
    "                                 return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa.invoke({\"query\": query})\n",
    "result['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template_prefix = \"\"\"You are a music recommender system that helps users find songs that match their preferences.\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "For each question, suggest three songs, with a short description of the song's genre, mood, and the reason why the user might like it.\n",
    "For each question, take into account the context and the personal information provided by the user.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\"\"\"\n",
    "\n",
    "user_info = \"\"\"This is what we know about the user, and you can use this information to better tune your research:\n",
    "Age: {age}\n",
    "Gender: {gender}\"\"\"\n",
    "\n",
    "template_suffix= \"\"\"Question: {question}\n",
    "Your response:\"\"\"\n",
    "\n",
    "user_info = user_info.format(age = 18, gender = 'female')\n",
    "\n",
    "COMBINED_PROMPT = template_prefix +'\\n'+ user_info +'\\n'+ template_suffix\n",
    "print(COMBINED_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate(\n",
    "    template=COMBINED_PROMPT, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=docsearch.as_retriever(),\n",
    "    return_source_documents=True, \n",
    "    chain_type_kwargs=chain_type_kwargs)\n",
    "query = \"I'm looking for a song similar by rapper like Eminem, 50 Cent. What could you suggest to me?\"\n",
    "result = qa({'query':query})\n",
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.get('source_documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"You are a music recommender system that helps users find songs that match their preferences.\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "For each question, suggest three songs, with a short description of the song's genre, mood, and the reason why the user might like it.\n",
    "For each question, take into account the context and the personal information provided by the user.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Your response:\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "llm=ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0, openai_api_key=api_key) \n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=docsearch.as_retriever(),\n",
    "    return_source_documents=True, \n",
    "    chain_type_kwargs=chain_type_kwargs)\n",
    "\n",
    "query = \"I'm looking for a song similar to pink floyd style. What could you suggest to me?\"\n",
    "result = qa.invoke({'query':query})\n",
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template_prefix = \"\"\"You are a music recommender system that helps users find songs that match their preferences.\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "For each question, suggest three songs, with a short description of the song's genre, mood, and the reason why the user might like it.\n",
    "For each question, take into account the context and the personal information provided by the user.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\"\"\"\n",
    "\n",
    "user_info = \"\"\"This is what we know about the user, and you can use this information to better tune your research:\n",
    "Age: {age}\n",
    "Gender: {gender}\"\"\"\n",
    "\n",
    "template_suffix= \"\"\"Question: {question}\n",
    "Your response:\"\"\"\n",
    "\n",
    "user_info = user_info.format(age = 18, gender = 'female')\n",
    "\n",
    "COMBINED_PROMPT = template_prefix +'\\n'+ user_info +'\\n'+ template_suffix\n",
    "print(COMBINED_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate(template=COMBINED_PROMPT, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=docsearch.as_retriever(),\n",
    "    return_source_documents=True, \n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")\n",
    "PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I'm looking for rap songs, artists like eminem and 50cent. What could you suggest to me?\"\n",
    "result = qa.invoke({'query':query})\n",
    "print(result['result'])\n",
    "print(result['source_documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
