{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import scipy\n",
    "import implicit\n",
    "\n",
    "import implicit\n",
    "from scipy.sparse import coo_matrix\n",
    "import scipy.sparse\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One very common problem to solve is when you have a number of users and a number of products, and you want to recommend which products are most likely to be useful for which users. There are many variations of this: for example, recommending movies (such as on Netflix), figuring out what to highlight for a user on a home page, deciding what stories to show in a social media feed, and so forth. There is a general solution to this problem, called collaborative filtering, which works like this: look at what products the current user has used or liked, find other users that have used or liked similar products, and then recommend other products that those users have used or liked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Non-personalized approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Top-250 tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Load and prepare the data\n",
    "triplet_columns = ['user_id', 'song_id', 'play_count']\n",
    "track_columns = ['track_id', 'song_id', 'artist', 'title']\n",
    "\n",
    "# Read datasets\n",
    "triplet_df = pl.read_csv('data/train_triplets.txt', separator='\\t', new_columns=triplet_columns, use_pyarrow=True)\n",
    "unique_tracks_df = pl.read_csv('data/p02_unique_tracks.csv', new_columns=track_columns, use_pyarrow=True)\n",
    "\n",
    "# Aggregate and join data\n",
    "song_play_counts = triplet_df.group_by('song_id').agg(pl.sum('play_count').alias('play_count')).sort('play_count', descending=True).limit(250)\n",
    "top_250_tracks = song_play_counts.join(unique_tracks_df, on='song_id').select('artist', 'title', 'play_count').with_row_index(name='index number')\n",
    "top_250_tracks = top_250_tracks.sort('play_count', descending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply .head(5) to the resulting dataframe of the top-250 tracks, the result should be exactly like this:\n",
    "artist title play_count\n",
    "- 0 Dwight Yoakam You're The One 726885\n",
    "- 1 Björk Undo 648239\n",
    "- 2 Kings Of Leon Revelry 527893\n",
    "- 3 Harmonia Sehr kosmisch 425463\n",
    "- 4 Barry Tuckwell/Academy of St Martin-in-the-Fie... Horn Concerto No. 4 in E flat K495: II. Romanc... 389880"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_250_tracks.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply .tail(5) to the resulting dataframe of the top-250 tracks, the result\n",
    "should be exactly like this:\n",
    "artist title play_count\n",
    "- 245 Triple Six Mafia Now I'm High_ Really High 35253\n",
    "- 246 The Red Jumpsuit Apparatus Face Down (Album Version) 35245\n",
    "- 247 Linkin Park New Divide (Album Version) 35191\n",
    "- 248 Selena Gomez & The Scene Naturally 35074\n",
    "- 249 Creedence Clearwater Revival Have You Ever Seen The Rain 34831\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_250_tracks.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Top-100 tracks by genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_column_names = ['track_id', 'majority_genre', 'minority_genre']\n",
    "tagtraum_genre_df = pd.read_csv('data/p02_msd_tagtraum_cd2.cls', sep='\\t', comment='#', names=genre_column_names)\n",
    "tagtraum_genre_df.drop(columns=['minority_genre'], axis=1, inplace=True)\n",
    "tagtraum_genre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_genre = pd.merge(pd.merge(tagtraum_genre_df, unique_tracks_df.to_pandas(), on='track_id'), triplet_df.to_pandas(), on='song_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_and_bottom_tracks(merged_df_genre, selected_genre):\n",
    "    # Filter by the specified genre\n",
    "    genre_subset = merged_df_genre[merged_df_genre['majority_genre'] == selected_genre]\n",
    "\n",
    "    # Aggregate play counts for each track in the selected genre\n",
    "    track_play_counts = genre_subset.groupby(['artist', 'title'])['play_count'].sum()\n",
    "\n",
    "    # Sort tracks by play count in descending order\n",
    "    sorted_tracks = track_play_counts.sort_values(ascending=False).head(100)\n",
    "\n",
    "    # Get the top 5 and bottom 5 tracks\n",
    "    top_tracks = sorted_tracks.head(5)\n",
    "    bottom_tracks = sorted_tracks.tail(5)\n",
    "\n",
    "    return top_tracks, bottom_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rock\n",
    "\n",
    "Apply .head(5) to the resulting dataframe of the top-100 tracks\n",
    "- for the genre, the result should be exactly like this:\n",
    "- artist title play_count\n",
    "- 0 Björk Undo 648239\n",
    "- 1 Kings Of Leon Revelry 527893\n",
    "- 2 Harmonia Sehr kosmisch 425463\n",
    "- 3 OneRepublic Secrets 292642\n",
    "- 4 Tub Ring Invalid 268353\n",
    "\n",
    "Apply .tail(5) to the resulting dataframe of the top-100 tracks\n",
    "for the genre, the result should be exactly like this:\n",
    "- artist title play_count\n",
    "- 95 Metric Gold Guns Girls 28148\n",
    "- 96 Pearl Jam Encore Break 27579\n",
    "- 97 Daughtry No Surprise 27187\n",
    "- 98 Eric Clapton Tears In Heaven 26999\n",
    "- 99 Nick Lowe All Men Are Liars 26683"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_genre = 'Rock'\n",
    "\n",
    "top_tracks, bottom_tracks = get_top_and_bottom_tracks(merged_df_genre, selected_genre)\n",
    "\n",
    "print(f\"Top 5 tracks for the genre: {selected_genre}\")\n",
    "top_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nBottom 5 tracks for the genre: {selected_genre}\")\n",
    "bottom_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rap\n",
    "\n",
    "**Apply .head(5) to the resulting dataframe of the top-100 tracks\n",
    "for the genre, the result should be exactly like this:**\n",
    "artist title play_count\n",
    "- 0 Alliance Ethnik Représente 241669\n",
    "- 1 Beastie Boys The Maestro 72381\n",
    "- 2 Eminem Without Me 63918\n",
    "- 3 Black Eyed Peas Imma Be 62438\n",
    "- 4 Kid Cudi Up Up & Away 59810\n",
    "\n",
    "**Apply .tail(5) to the resulting dataframe of the top-100 tracks\n",
    "for the genre, the result should be exactly like this:**\n",
    "artist title play_count\n",
    "- 95 Shwayze Buzzin' 7384\n",
    "- 96 Orishas El Kilo 7324\n",
    "- 97 Snoop Dogg Sexual Eruption 7171\n",
    "- 98 Bone Thugs-N-Harmony Tha Crossroads 7124\n",
    "- 99 Orishas Habana 6998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_genre = 'Rap'\n",
    "\n",
    "top_tracks, bottom_tracks = get_top_and_bottom_tracks(merged_df_genre, selected_genre)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Top 5 tracks for the genre: {selected_genre}\")\n",
    "top_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nBottom 5 tracks for the genre: {selected_genre}\")\n",
    "bottom_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Electronic\n",
    "\n",
    "**Apply .head(5) to the resulting dataframe of the top-100 tracks\n",
    "for the genre, the result should be exactly like this:**\n",
    "artist title play_count\n",
    "- 0 Southside Spinners Luvstruck 84225\n",
    "- 1 The Black Keys Tighten Up 81179\n",
    "- 2 Deadmau5 Ghosts 'n' Stuff (Original Instrumental Mix) 63951\n",
    "- 3 Daft Punk Harder Better Faster Stronger 63170\n",
    "- 4 Clara Hill Clara meets Slope - Hard To Say 58887\n",
    "\n",
    "**Apply .tail(5) to the resulting dataframe of the top-100 tracks\n",
    "for the genre, the result should be exactly like this:**\n",
    "artist title play_count\n",
    "- 95 Nicolette No Government 9541\n",
    "- 96 Two Door Cinema Club Eat That Up_ It's Good For You 9524\n",
    "- 97 Moby Why Does My Heart Feel So Bad? (2006 Digital R... 9491\n",
    "- 98 Death In Vegas Girls 9490\n",
    "- 99 Johan Gielen Flash 9431"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_genre = 'Electronic'\n",
    "\n",
    "top_tracks, bottom_tracks = get_top_and_bottom_tracks(merged_df_genre, selected_genre)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Top 5 tracks for the genre: {selected_genre}\")\n",
    "top_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nBottom 5 tracks for the genre: {selected_genre}\")\n",
    "bottom_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should return on a given keyword (love, war, happiness) a dataframe (50tracks) with the following fields: index number, artist name, track title, play count. The table should be sorted by the play count descendingly. Try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1. baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mxm_dataset_path = 'data/mxm_dataset_train.txt'\n",
    "merged_songs_path = 'data/songs.csv'\n",
    "\n",
    "\n",
    "if not Path('data/songs.csv').exists():\n",
    "    print('Merging songs...')\n",
    "    triplet_columns = ['user_id', 'song_id', 'play_count']\n",
    "    track_columns = ['track_id', 'song_id', 'artist', 'title']\n",
    "    \n",
    "    triplet_df = pl.read_csv('data/train_triplets.txt', separator='\\t', new_columns=triplet_columns, use_pyarrow=True)\n",
    "    unique_tracks_df = pl.read_csv('data/p02_unique_tracks.csv', new_columns=track_columns)\n",
    "    triplet_df = triplet_df.group_by('song_id').agg(pl.sum('play_count').alias('play_count')).sort('play_count', descending=True)\n",
    "    mergerd_songs = triplet_df.join(unique_tracks_df, on='song_id', how='left').select('track_id', 'artist', 'title', 'play_count')\n",
    "    mergerd_songs.write_csv('data/songs.csv')\n",
    "else:\n",
    "    print('Reading songs...')\n",
    "    mergerd_songs = pl.read_csv(merged_songs_path, use_pyarrow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergerd_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MXMDataLoader:\n",
    "    def __init__(self, dataset_path_mxm, mergerd_songs):\n",
    "        self.dataset_path = dataset_path_mxm\n",
    "        self.songs = mergerd_songs\n",
    "        \n",
    "    def load(self):\n",
    "        top_words = []\n",
    "        filtered_tracks = []\n",
    "\n",
    "        with open(self.dataset_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                if line.startswith('#') or line.strip() == '':\n",
    "                    continue\n",
    "                elif line.startswith('%'):\n",
    "                    top_words = line[1:].strip().split(',')\n",
    "                else:\n",
    "                    elements = line.strip().split(',')\n",
    "                    track_id = elements[0]\n",
    "                    word_counts = {int(count.split(':')[0]) - 1: int(count.split(':')[1]) for count in elements[2:]}\n",
    "                    filtered_tracks.append((track_id, word_counts))\n",
    "        self.top_words = top_words\n",
    "        self.filtered_tracks = filtered_tracks\n",
    "        \n",
    "    def get_song_lyrics(self, track_id):\n",
    "        def get_words(top_words, word_counts):\n",
    "            return {top_words[index]:count for index, count in word_counts.items()}\n",
    "            \n",
    "        \n",
    "        for track in self.filtered_tracks:\n",
    "            if track[0] == track_id:\n",
    "                return get_words(self.top_words, track[1])\n",
    "        raise ValueError(f\"Track ID '{track_id}' not found in the dataset.\")\n",
    "    \n",
    "    def get_sorted_tracks_by_keyword(self, keyword, threshold):\n",
    "        \n",
    "        try:\n",
    "            keyword_index = self.top_words.index(keyword)\n",
    "        except ValueError:\n",
    "            print(f\"Keyword '{keyword}' not found in the dataset.\")\n",
    "            return\n",
    "            \n",
    "        filtered_tracks = []\n",
    "        for idx, (track_id, word_counts) in enumerate(self.filtered_tracks): \n",
    "            keyword_count = word_counts.get(keyword_index, 0)\n",
    "            if keyword_count >= threshold:\n",
    "                row_df = self.songs.filter(pl.col('track_id') == track_id)\n",
    "                if len(row_df) > 0:\n",
    "                    _ , artist, title, play_count = row_df[0].row(0)\n",
    "                    filtered_tracks.append((idx, track_id, artist, title, play_count, keyword_count))\n",
    "        print(\"Done ✅ filtering tracks by keyword.\")    \n",
    "        filtered_tracks_df = pl.DataFrame(filtered_tracks, schema=['index_number', 'track_id' ,'artist', 'title', 'play_count', 'keyword_count']).sort('play_count', descending=True).head(50)\n",
    "        return filtered_tracks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mxm_loader = MXMDataLoader(mxm_dataset_path, mergerd_songs)\n",
    "mxm_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try ‘love’ as the keyword and look through the lyrics of 3 random tracks given in the list of recommendations – do they have ‘love’ in the lyrics?\n",
    "tracks = mxm_loader.get_sorted_tracks_by_keyword('life', 6)\n",
    "tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mxm_loader.get_song_lyrics('TRJRECT12903CBADA3')['love']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "idx = random.randint(0, len(tracks) - 1)\n",
    "track_id = 'TROHFJK12903CC4BCE'\n",
    "print(f\"Track ID: {track_id}\")\n",
    "print(f\"Lyrics: {mxm_loader.get_song_lyrics(track_id)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If an incorrect keyword is given, the exception is handled\n",
    "incorrect_keyword_tracks = mxm_loader.get_sorted_tracks_by_keyword('incorrect_keyword', 6)\n",
    "incorrect_keyword_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2. word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "model_name = 'glove-wiki-gigaword-300'\n",
    "wv = api.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    vec_love = wv['love']\n",
    "except KeyError:\n",
    "    print(\"The word 'love' does not appear in this model\")\n",
    "vec_love"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MXMDataLoaderW2V:\n",
    "    def __init__(self, dataset_path_mxm, mergerd_songs, word_vectors):\n",
    "        self.dataset_path = dataset_path_mxm\n",
    "        self.songs = mergerd_songs\n",
    "        self.word_vectors = word_vectors\n",
    "        self.top_words = []\n",
    "        self.filtered_tracks = []\n",
    "\n",
    "    def load(self):\n",
    "        with open(self.dataset_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                if line.startswith('#') or line.strip() == '':\n",
    "                    continue\n",
    "                elif line.startswith('%'):\n",
    "                    self.top_words = line[1:].strip().split(',')\n",
    "                else:\n",
    "                    elements = line.strip().split(',')\n",
    "                    track_id = elements[0]\n",
    "                    word_counts = {int(count.split(':')[0]) - 1 : int(count.split(':')[1]) for count in elements[2:]}\n",
    "                    self.filtered_tracks.append((track_id, word_counts))\n",
    "\n",
    "    def get_similar_keywords(self, keyword, top_n=5):\n",
    "        \"\"\"Get top_n similar words to the given keyword.\"\"\"\n",
    "        try:\n",
    "            similar_words = self.word_vectors.most_similar(positive=[keyword], topn=top_n)\n",
    "            return [keyword] + [word for word, _ in similar_words]  # Include the keyword itself\n",
    "        except KeyError:\n",
    "            print(f\"Keyword '{keyword}' not found in the word2vec model.\")\n",
    "            return [keyword]\n",
    "\n",
    "    def get_sorted_tracks_by_keyword(self, keyword, threshold, max_tracks=50):\n",
    "        similar_keywords = self.get_similar_keywords(keyword)\n",
    "        print(f\"Similar keywords to '{keyword}': {similar_keywords}\")\n",
    "        similar_keyword_indices = [self.top_words.index(word) for word in similar_keywords if word in self.top_words]\n",
    "\n",
    "        filtered_tracks = []\n",
    "        for track_id, word_counts in self.filtered_tracks:\n",
    "            total_count = sum(word_counts.get(idx, 0) for idx in similar_keyword_indices[:5])\n",
    "            if total_count >= threshold:\n",
    "                row_df = self.songs.filter(pl.col('track_id') == track_id)\n",
    "                if len(row_df) > 0:\n",
    "                    _ , artist, title, play_count = row_df[0].row(0)\n",
    "                    filtered_tracks.append((idx, track_id, artist, title, play_count, total_count))\n",
    "        print(\"Done ✅ filtering tracks by keyword.\")    \n",
    "        filtered_tracks_df = pl.DataFrame(filtered_tracks, schema=['index_number', 'track_id' ,'artist', 'title', 'play_count', 'keyword_count']).sort('play_count', descending=True).head(50)\n",
    "                \n",
    "        return filtered_tracks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try ‘love’ as the keyword and look through the lyrics of 3 random tracks given in the list of recommendations – do they have ‘love’ in the lyrics?\n",
    "mxm_loader = MXMDataLoaderW2V(mxm_dataset_path, mergerd_songs, wv)\n",
    "mxm_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = mxm_loader.get_sorted_tracks_by_keyword('happy', 6, max_tracks=50)\n",
    "print(tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3. Classification Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "class MXMDataLoaderClassification:\n",
    "    def __init__(self, dataset_path_mxm, merged_songs, wv):\n",
    "        self.dataset_path = dataset_path_mxm\n",
    "        self.songs = merged_songs\n",
    "        self.top_words = []\n",
    "        self.filtered_tracks = []\n",
    "        self.word_vectors = wv\n",
    "\n",
    "    def load(self):\n",
    "        with open(self.dataset_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                if line.startswith('#') or line.strip() == '':\n",
    "                    continue\n",
    "                elif line.startswith('%'):\n",
    "                    self.top_words = line[1:].strip().split(',')\n",
    "                else:\n",
    "                    elements = line.strip().split(',')\n",
    "                    track_id = elements[0]\n",
    "                    word_counts = {int(count.split(':')[0]) - 1: int(count.split(':')[1]) for count in elements[2:]}\n",
    "                    self.filtered_tracks.append((track_id, word_counts))\n",
    "\n",
    "    def classify_tracks_by_keywords(self, keywords):\n",
    "        tracks_classification = []\n",
    "        # Create a dictionary to find indices of keywords in top_words\n",
    "        keyword_indices = {keyword: self.top_words.index(keyword) for keyword in keywords if keyword in self.top_words}\n",
    "\n",
    "        for track_id, word_counts in self.filtered_tracks:\n",
    "            keyword_presence = {keyword: word_counts.get(idx, 0) for keyword, idx in keyword_indices.items()}\n",
    "\n",
    "            # Determine the most prevalent keyword based on counts\n",
    "            if keyword_presence:\n",
    "                most_prevalent_keyword = max(keyword_presence, key=keyword_presence.get)\n",
    "                max_count = keyword_presence[most_prevalent_keyword]\n",
    "                if max_count > 0:  # Only consider tracks where the keyword count is greater than zero\n",
    "                    row_df = self.songs.filter(pl.col('track_id') == track_id)\n",
    "                    if len(row_df) > 0:\n",
    "                        _, artist, title, play_count = row_df[0].row(0)\n",
    "                        tracks_classification.append((track_id, artist, title, play_count, most_prevalent_keyword))\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        classification_df = pl.DataFrame(tracks_classification, schema=['track_id', 'artist', 'title', 'play_count', 'label'])\n",
    "        self.classification_df = classification_df\n",
    "        return classification_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"love\", \"war\", \"happiness\", \"loneliness\", \"money\"]\n",
    "loader = MXMDataLoaderClassification(mxm_dataset_path, mergerd_songs)\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_tracks = loader.classify_tracks_by_keywords(keywords)\n",
    "classified_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_tracks['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "class MXMDataLoaderClassification:\n",
    "    def __init__(self, dataset_path_mxm):\n",
    "        self.dataset_path = dataset_path_mxm\n",
    "        self.top_words = []\n",
    "        self.filtered_tracks = []\n",
    "\n",
    "    def load(self):\n",
    "        with open(self.dataset_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                if line.startswith('#') or line.strip() == '':\n",
    "                    continue\n",
    "                elif line.startswith('%'):\n",
    "                    self.top_words = line[1:].strip().split(',')\n",
    "                else:\n",
    "                    elements = line.strip().split(',')\n",
    "                    track_id = elements[0]\n",
    "                    word_counts = {int(count.split(':')[0]) - 1: int(count.split(':')[1]) for count in elements[2:]}\n",
    "                    self.filtered_tracks.append((track_id, word_counts))\n",
    "    \n",
    "    def train(self):\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        for track_id, word_counts in self.filtered_tracks:\n",
    "            word_counts_vec = [word_counts.get(idx, 0) for idx in range(len(loader.top_words))]\n",
    "            X.append(word_counts_vec[:728])\n",
    "            label = self.labeled_tracks.filter(pl.col('track_id') == track_id)['label'].item(0)\n",
    "            y.append(label)\n",
    "            \n",
    "        tfidf_transformer = TfidfTransformer()\n",
    "        tfidf_matrix = tfidf_transformer.fit_transform(X)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, y, test_size=0.2, random_state=42)\n",
    "        print(\"Training and testing data shapes:\",  X_train.shape, X_test.shape, len(y_train), len(y_test))\n",
    "\n",
    "        classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        return classifier\n",
    "\n",
    "    def label_tracks(self, categories):\n",
    "        track_labels = []\n",
    "\n",
    "        # Map keywords to their indices for quick lookup\n",
    "        keyword_to_index = {word: idx for idx, word in enumerate(self.top_words)}\n",
    "\n",
    "        for track_id, word_counts in self.filtered_tracks:\n",
    "            category_counts = {category: 0 for category in categories}\n",
    "\n",
    "            # Accumulate counts for each category based on associated keywords\n",
    "            for category, keywords in categories.items():\n",
    "                for keyword in keywords:\n",
    "                    idx = keyword_to_index.get(keyword)\n",
    "                    if idx is not None:\n",
    "                        category_counts[category] += word_counts.get(idx, 0)\n",
    "\n",
    "            # Determine the category with the highest count\n",
    "            if category_counts:\n",
    "                dominant_category = max(category_counts, key=category_counts.get)\n",
    "                track_labels.append((track_id, dominant_category))\n",
    "\n",
    "        labeled_df = pl.DataFrame(track_labels, schema=['track_id', 'label'])\n",
    "        self.labeled_tracks = labeled_df\n",
    "        return labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = MXMDataLoaderClassification(mxm_dataset_path)\n",
    "loader.load()\n",
    "categories = {\n",
    "    \"love\": [\"love\", \"heart\"],\n",
    "    \"war\": [\"war\", \"battle\"],\n",
    "    \"money\": [\"money\", \"cash\"],\n",
    "    \"loneliness\": [\"lonely\", \"alone\"]\n",
    "}\n",
    "labeled_tracks = loader.label_tracks(categories)\n",
    "print(labeled_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## 3. People similar to you listen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tracks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading songs...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>track_id</th>\n",
       "      <th>song</th>\n",
       "      <th>play_count</th>\n",
       "      <th>user_idx</th>\n",
       "      <th>song_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOAPDEY12A81C210A9</td>\n",
       "      <td>TRIRLYL128F42539D1</td>\n",
       "      <td>Nothing from Nothing - Billy Preston</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBBMDR12A8C13253B</td>\n",
       "      <td>TRMHBXZ128F4238406</td>\n",
       "      <td>Entre Dos Aguas - Paco De Lucia</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBFNSP12AF72A0E22</td>\n",
       "      <td>TRYQMNI128F147C1C7</td>\n",
       "      <td>Under Cold Blue Stars - Josh Rouse</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBFOVM12A58A7D494</td>\n",
       "      <td>TRAHZNE128F9341B86</td>\n",
       "      <td>Riot Radio (Soundtrack Version) - The Dead 60s</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBNZDC12A6D4FC103</td>\n",
       "      <td>TRJPXGD128F92F17D7</td>\n",
       "      <td>Sin límites (I) - Amset</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49664522</th>\n",
       "      <td>b7815dbb206eb2831ce0fe040d0aa537e2e800f7</td>\n",
       "      <td>SOUHHHH12AF729E4AF</td>\n",
       "      <td>TRKUAEO128F933ABFC</td>\n",
       "      <td>We're Back - Eminem / Obie Trice / Stat Quo / ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1019317</td>\n",
       "      <td>4979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49664523</th>\n",
       "      <td>b7815dbb206eb2831ce0fe040d0aa537e2e800f7</td>\n",
       "      <td>SOUJVIT12A8C1451C1</td>\n",
       "      <td>TRRNFHH128F92D262D</td>\n",
       "      <td>Savior - Rise Against</td>\n",
       "      <td>1</td>\n",
       "      <td>1019317</td>\n",
       "      <td>1773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49664524</th>\n",
       "      <td>b7815dbb206eb2831ce0fe040d0aa537e2e800f7</td>\n",
       "      <td>SOUSMXX12AB0185C24</td>\n",
       "      <td>TRSLDDC12903CC36E7</td>\n",
       "      <td>OMG - Usher featuring will.i.am</td>\n",
       "      <td>1</td>\n",
       "      <td>1019317</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49664525</th>\n",
       "      <td>b7815dbb206eb2831ce0fe040d0aa537e2e800f7</td>\n",
       "      <td>SOWYSKH12AF72A303A</td>\n",
       "      <td>TRNJQAM128F14557AF</td>\n",
       "      <td>Downfall (Album Version) - matchbox twenty</td>\n",
       "      <td>3</td>\n",
       "      <td>1019317</td>\n",
       "      <td>3086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49664526</th>\n",
       "      <td>b7815dbb206eb2831ce0fe040d0aa537e2e800f7</td>\n",
       "      <td>SOYYFLV12A58A7A88F</td>\n",
       "      <td>TRKSGQU128F14824E9</td>\n",
       "      <td>Lying From You (Album Version) - Linkin Park</td>\n",
       "      <td>1</td>\n",
       "      <td>1019317</td>\n",
       "      <td>1405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49664527 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_id             song_id  \\\n",
       "0         b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAPDEY12A81C210A9   \n",
       "1         b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBBMDR12A8C13253B   \n",
       "2         b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBFNSP12AF72A0E22   \n",
       "3         b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBFOVM12A58A7D494   \n",
       "4         b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBNZDC12A6D4FC103   \n",
       "...                                            ...                 ...   \n",
       "49664522  b7815dbb206eb2831ce0fe040d0aa537e2e800f7  SOUHHHH12AF729E4AF   \n",
       "49664523  b7815dbb206eb2831ce0fe040d0aa537e2e800f7  SOUJVIT12A8C1451C1   \n",
       "49664524  b7815dbb206eb2831ce0fe040d0aa537e2e800f7  SOUSMXX12AB0185C24   \n",
       "49664525  b7815dbb206eb2831ce0fe040d0aa537e2e800f7  SOWYSKH12AF72A303A   \n",
       "49664526  b7815dbb206eb2831ce0fe040d0aa537e2e800f7  SOYYFLV12A58A7A88F   \n",
       "\n",
       "                    track_id  \\\n",
       "0         TRIRLYL128F42539D1   \n",
       "1         TRMHBXZ128F4238406   \n",
       "2         TRYQMNI128F147C1C7   \n",
       "3         TRAHZNE128F9341B86   \n",
       "4         TRJPXGD128F92F17D7   \n",
       "...                      ...   \n",
       "49664522  TRKUAEO128F933ABFC   \n",
       "49664523  TRRNFHH128F92D262D   \n",
       "49664524  TRSLDDC12903CC36E7   \n",
       "49664525  TRNJQAM128F14557AF   \n",
       "49664526  TRKSGQU128F14824E9   \n",
       "\n",
       "                                                       song  play_count  \\\n",
       "0                      Nothing from Nothing - Billy Preston           1   \n",
       "1                           Entre Dos Aguas - Paco De Lucia           2   \n",
       "2                        Under Cold Blue Stars - Josh Rouse           1   \n",
       "3            Riot Radio (Soundtrack Version) - The Dead 60s           1   \n",
       "4                                   Sin límites (I) - Amset           1   \n",
       "...                                                     ...         ...   \n",
       "49664522  We're Back - Eminem / Obie Trice / Stat Quo / ...           2   \n",
       "49664523                              Savior - Rise Against           1   \n",
       "49664524                    OMG - Usher featuring will.i.am           1   \n",
       "49664525         Downfall (Album Version) - matchbox twenty           3   \n",
       "49664526       Lying From You (Album Version) - Linkin Park           1   \n",
       "\n",
       "          user_idx  song_idx  \n",
       "0                0         0  \n",
       "1                0         1  \n",
       "2                0         2  \n",
       "3                0         3  \n",
       "4                0         4  \n",
       "...            ...       ...  \n",
       "49664522   1019317      4979  \n",
       "49664523   1019317      1773  \n",
       "49664524   1019317       219  \n",
       "49664525   1019317      3086  \n",
       "49664526   1019317      1405  \n",
       "\n",
       "[49664527 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not Path('data/songs_filtered.csv').exists():\n",
    "    \n",
    "    print('Merging songs...')\n",
    "    songs = pd.merge(triplet_df.to_pandas(), unique_tracks_df.to_pandas(), on='song_id', how='left')\n",
    "    songs['song'] = songs['title']+' - ' + songs['artist']\n",
    "    songs = songs[['user_id', 'song_id', 'track_id', 'song', 'play_count']]\n",
    "    songs.to_csv('data/songs_filtered.csv')\n",
    "else:\n",
    "    print('Reading songs...')\n",
    "    songs = pd.read_csv('data/songs_filtered.csv')\n",
    "    songs['user_idx'] = pd.factorize(songs['user_id'])[0]\n",
    "    songs['song_idx'] = pd.factorize(songs['song_id'])[0]\n",
    "\n",
    "songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicData:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.song_id_to_name = pd.Series(data.song.values, index=data.song_id).to_dict()\n",
    "\n",
    "    def get_user_songs(self, user_id):\n",
    "        user_data = self.data[self.data['user_id'] == user_id]\n",
    "        user_songs = [self.song_id_to_name[song_id] for song_id in user_data['song_id'].unique()]\n",
    "        return user_songs\n",
    "\n",
    "    def get_song_users(self, song_id):\n",
    "        song_data = self.data[self.data['song_id'] == song_id]\n",
    "        song_users = song_data['user_id'].unique()\n",
    "        return song_users\n",
    "\n",
    "    def get_song_name(self, song_id):\n",
    "        return self.song_id_to_name.get(song_id, \"Song ID not found in data\")\n",
    "\n",
    "    def get_top_songs(self, n=10):\n",
    "        top_songs = self.data['song_id'].value_counts()[:n].index.tolist()\n",
    "        return top_songs\n",
    "\n",
    "    def get_top_users(self, n=10):\n",
    "        top_users = self.data['user_id'].value_counts()[:n].index.tolist()\n",
    "        return top_users\n",
    "    \n",
    "    \n",
    "    def get_recommendations(self, user_id, n=10):\n",
    "        user_songs = self.get_user_songs(user_id)\n",
    "        all_songs = self.data['song_id'].unique()\n",
    "        recommendations = [song_id for song_id in all_songs if song_id not in user_songs][:n]\n",
    "        return recommendations\n",
    "\n",
    "\n",
    "music_data = MusicData(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_idx</th>\n",
       "      <th>song_idx</th>\n",
       "      <th>play_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49664522</th>\n",
       "      <td>1019317</td>\n",
       "      <td>4979</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49664523</th>\n",
       "      <td>1019317</td>\n",
       "      <td>1773</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49664524</th>\n",
       "      <td>1019317</td>\n",
       "      <td>219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49664525</th>\n",
       "      <td>1019317</td>\n",
       "      <td>3086</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49664526</th>\n",
       "      <td>1019317</td>\n",
       "      <td>1405</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49664527 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_idx  song_idx  play_count\n",
       "0                0         0           1\n",
       "1                0         1           2\n",
       "2                0         2           1\n",
       "3                0         3           1\n",
       "4                0         4           1\n",
       "...            ...       ...         ...\n",
       "49664522   1019317      4979           2\n",
       "49664523   1019317      1773           1\n",
       "49664524   1019317       219           1\n",
       "49664525   1019317      3086           3\n",
       "49664526   1019317      1405           1\n",
       "\n",
       "[49664527 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = songs[['user_idx', 'song_idx', 'play_count']]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.set_index([\"user_idx\", \"song_idx\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>play_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_idx</th>\n",
       "      <th>song_idx</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   play_count\n",
       "user_idx song_idx            \n",
       "0        0                  1\n",
       "         1                  2\n",
       "         2                  1\n",
       "         3                  1\n",
       "         4                  1\n",
       "         5                  2\n",
       "         6                  1\n",
       "         7                  1\n",
       "         8                  1\n",
       "         8                  1\n",
       "         9                  1\n",
       "         10                 1\n",
       "         11                 1\n",
       "         12                 5\n",
       "         13                 1\n",
       "         14                 1\n",
       "         15                 1\n",
       "         16                 1\n",
       "         17                 1\n",
       "         18                 1\n",
       "         19                 1\n",
       "         20                 1\n",
       "         21                 1\n",
       "         22                 1\n",
       "         23                 1\n",
       "         24                 1\n",
       "         25                 1\n",
       "         26                 1\n",
       "         27                 1\n",
       "         28                 1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0],\n",
       "      dtype='int64', name='user_idx')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.index.get_level_values(0)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([     0,      1,      2,      3,      4,      5,      6,      7,      8,\n",
       "            8,\n",
       "       ...\n",
       "         5322,  13096, 142665,  23083,  70144,   4979,   1773,    219,   3086,\n",
       "         1405],\n",
       "      dtype='int64', name='song_idx', length=49664527)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.index.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "coo = scipy.sparse.coo_matrix( (X.play_count.astype(float), (X.index.get_level_values(0), X.index.get_level_values(1),),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/m0saan/miniforge3/envs/fastai/lib/python3.11/site-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 10 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n"
     ]
    }
   ],
   "source": [
    "implict_model = implicit.als.AlternatingLeastSquares(\n",
    "    factors=50, iterations=10, regularization=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3b306f9dac438bb1696ee9bfbcfc62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "implict_model.fit(coo.tocsr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "user_items needs to be a CSR sparse matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [music_data\u001b[38;5;241m.\u001b[39msong_name(song_id) \u001b[38;5;28;01mfor\u001b[39;00m song_id \u001b[38;5;129;01min\u001b[39;00m recommended_song_ids]\n\u001b[1;32m     10\u001b[0m userId \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb7815dbb206eb2831ce0fe040d0aa537e2e800f7\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSongs recommended for a user:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mrecommend_songs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimplict_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msongs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserId\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m, in \u001b[0;36mrecommend_songs\u001b[0;34m(model, songs, user_id, matrix, n)\u001b[0m\n\u001b[1;32m      3\u001b[0m user_idx \u001b[38;5;241m=\u001b[39m songs[songs\u001b[38;5;241m.\u001b[39muser_id \u001b[38;5;241m==\u001b[39m user_id]\u001b[38;5;241m.\u001b[39muser_idx\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# songs_ids, scores = implict_model.recommend(user_idx, coo.tocsr()[n], N=n)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecommend\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m recommended_song_ids \u001b[38;5;241m=\u001b[39m [songs\u001b[38;5;241m.\u001b[39mloc[songs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msong_idx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m idx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msong_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miat[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m idx, _ \u001b[38;5;129;01min\u001b[39;00m recommendations]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [music_data\u001b[38;5;241m.\u001b[39msong_name(song_id) \u001b[38;5;28;01mfor\u001b[39;00m song_id \u001b[38;5;129;01min\u001b[39;00m recommended_song_ids]\n",
      "File \u001b[0;32m~/miniforge3/envs/fastai/lib/python3.11/site-packages/implicit/cpu/matrix_factorization_base.py:46\u001b[0m, in \u001b[0;36mMatrixFactorizationBase.recommend\u001b[0;34m(self, userid, user_items, N, filter_already_liked_items, filter_items, recalculate_user, items)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filter_already_liked_items \u001b[38;5;129;01mor\u001b[39;00m recalculate_user:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(user_items, csr_matrix):\n\u001b[0;32m---> 46\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_items needs to be a CSR sparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m     user_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(userid) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(userid)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_items\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m user_count:\n",
      "\u001b[0;31mValueError\u001b[0m: user_items needs to be a CSR sparse matrix"
     ]
    }
   ],
   "source": [
    "def recommend_songs(model, songs, user_id, matrix, n=10):\n",
    "    \n",
    "    user_idx = songs[songs.user_id == user_id].user_idx.values[0]\n",
    "    # songs_ids, scores = implict_model.recommend(user_idx, coo.tocsr()[n], N=n)\n",
    "\n",
    "    recommendations = model.recommend(user_idx, matrix, N=n)\n",
    "    recommended_song_ids = [songs.loc[songs['song_idx'] == idx, 'song_id'].iat[0] for idx, _ in recommendations]\n",
    "    return [music_data.song_name(song_id) for song_id in recommended_song_ids]\n",
    "\n",
    "userId = 'b7815dbb206eb2831ce0fe040d0aa537e2e800f7'\n",
    "print(\"Songs recommended for a user:\", recommend_songs(implict_model, songs, userId, coo, n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_songs(model, songs, user_id, matrix, n=10):\n",
    "    \n",
    "    user_idx = songs[songs.user_id == user_id].user_idx.values[0]\n",
    "    # songs_ids, scores = implict_model.recommend(user_idx, coo.tocsr()[n], N=n)\n",
    "\n",
    "    songs_ids, scores = model.recommend(user_idx, matrix.tocsr()[n], N=n)\n",
    "    songs_ids = songs[songs.song_idx.isin(songs_ids)].song_id.unique()\n",
    "    recommended_songs = [music_data.get_song_name(song_id) for song_id in songs_ids]\n",
    "    \n",
    "    # check if the user has already listened to the recommended songs and remove them\n",
    "    user_songs = music_data.get_user_songs(user_id)\n",
    "    recommended_songs = [song for song in recommended_songs if song not in user_songs]\n",
    "    return recommended_songs[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# write a function like def recommend_songs(model, songs, user_id, matrix, n=10) that does the following:\n",
    "\n",
    "# Try songId SOWYSKH12AF72A303A\n",
    "# The recommendation list contains 10 tracks in the format described in the subject?\n",
    "# The list should not contain the track that was given as the argument\n",
    "# While training the model the average p@k was greater than 10%?\n",
    "\n",
    "\n",
    " \n",
    "def recommend_songs_by_song_id(model, songs, song_id, matrix, n=10):\n",
    "    song_idx = songs[songs.song_id == song_id].song_idx.values[0]    \n",
    "    itemids, scores = implict_model.similar_items(itemid=118)\n",
    "    itemids\n",
    "    itemids = songs[songs.song_idx.isin(itemids)].song_id.unique()\n",
    "    itemids\n",
    "    [music_data.get_song_name(item_id) for item_id in itemids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'implict_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m recommend_songs(\u001b[43mimplict_model\u001b[49m, songs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb7815dbb206eb2831ce0fe040d0aa537e2e800f7\u001b[39m\u001b[38;5;124m'\u001b[39m, coo, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'implict_model' is not defined"
     ]
    }
   ],
   "source": [
    "recommend_songs(implict_model, songs, 'b7815dbb206eb2831ce0fe040d0aa537e2e800f7', coo, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userId = 'b7815dbb206eb2831ce0fe040d0aa537e2e800f7'\n",
    "user_id = songs[songs.user_id == userId].user_idx.values[0]\n",
    "n = 10\n",
    "songs_ids, scores = implict_model.recommend(user_id, coo.tocsr()[n], N=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_ids = songs[songs.song_idx.isin(songs_ids)].song_id.unique()\n",
    "[music_data.get_song_name(song_id) for song_id in songs_ids[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_data.get_user_songs(userId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemids, scores = implict_model.similar_items(itemid=118)\n",
    "itemids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemids = songs[songs.song_idx.isin(itemids)].song_id.unique()\n",
    "itemids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[music_data.get_song_name(item_id) for item_id in itemids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refacored Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import implicit\n",
    "from scipy.sparse import coo_matrix\n",
    "import scipy.sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class MusicData:\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe\n",
    "        self.song_id_to_name = pd.Series(dataframe['song'].values, index=dataframe['song_id']).to_dict()\n",
    "\n",
    "    def get_songs_for_user(self, user_id):\n",
    "        user_songs = self.data[self.data['user_id'] == user_id]['song_id'].unique()\n",
    "        return [self.song_id_to_name.get(song_id, \"Song ID not found\") for song_id in user_songs]\n",
    "\n",
    "    def get_users_for_song(self, song_id):\n",
    "        return self.data[self.data['song_id'] == song_id]['user_id'].unique()\n",
    "\n",
    "    def song_name(self, song_id):\n",
    "        return self.song_id_to_name.get(song_id, \"Song ID not found in data\")\n",
    "\n",
    "    def top_songs(self, n=10):\n",
    "        return self.data['song_id'].value_counts().head(n).index.tolist()\n",
    "\n",
    "    def top_users(self, n=10):\n",
    "        return self.data['user_id'].value_counts().head(n).index.tolist()\n",
    "\n",
    "def prepare_data():\n",
    "    path = Path('data/songs_filtered.csv')\n",
    "    if not path.exists():\n",
    "        songs = pd.merge(triplet_df.to_pandas(), unique_tracks_df.to_pandas(), on='song_id', how='left')\n",
    "        songs['song'] = songs['title'] + ' - ' + songs['artist']\n",
    "        songs = songs[['user_id', 'song_id', 'track_id', 'song', 'play_count']]\n",
    "        songs.to_csv(path, index=False)\n",
    "    else:\n",
    "        songs = pd.read_csv(path)\n",
    "\n",
    "    songs['user_idx'] = pd.factorize(songs['user_id'])[0]\n",
    "    songs['song_idx'] = pd.factorize(songs['song_id'])[0]\n",
    "    return songs\n",
    "\n",
    "\n",
    "def create_sparse_matrix(data):\n",
    "    \"\"\" Converts a DataFrame back to a sparse matrix. \"\"\"\n",
    "    ratings_coo_matrix = coo_matrix((data['play_count'], (data['user_idx'], data['song_idx'])), \n",
    "                      shape=(data['user_idx'].max() + 1, data['song_idx'].max() + 1))\n",
    "    return ratings_coo_matrix.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = prepare_data()\n",
    "music_data = MusicData(songs)\n",
    "songs = songs[['user_id', 'user_idx', 'song_idx', 'play_count']]\n",
    "all_data = create_sparse_matrix(songs[['user_idx', 'song_idx', 'play_count']])\n",
    "# train_data, test_data = train_test_split(songs, test_size=0.2, random_state=42)\n",
    "\n",
    "# train_matrix = create_sparse_matrix(train_data)\n",
    "# test_matrix = create_sparse_matrix(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path('data/train_matrix.npz').exists():\n",
    "    print('Saving data...')\n",
    "    songs.to_csv('data/songs.csv', index=False)\n",
    "    scipy.sparse.save_npz('data/train_matrix.npz', all_data)\n",
    "    scipy.sparse.save_npz('data/coo_matrix.npz', coo)\n",
    "else:\n",
    "    print('Loading data...')\n",
    "    all_data = scipy.sparse.load_npz('data/train_matrix.npz')\n",
    "    songs = pd.read_csv('data/songs.csv')\n",
    "    coo = scipy.sparse.load_npz('data/coo_matrix.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"{np.allclose(all_data.toarray()[:100], coo.toarray()[:100])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = implicit.als.AlternatingLeastSquares(factors=50, iterations=10, regularization=0.01)\n",
    "model.fit(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_songs(model, songs, user_id, matrix, n=10):\n",
    "    \n",
    "    user_idx = songs[songs.user_id == user_id].user_idx.values[0]\n",
    "    # songs_ids, scores = implict_model.recommend(user_idx, coo.tocsr()[n], N=n)\n",
    "\n",
    "    recommendations = model.recommend(user_idx, matrix, N=n)\n",
    "    recommended_song_ids = [songs.loc[songs['song_idx'] == idx, 'song_id'].iat[0] for idx, _ in recommendations]\n",
    "    return [music_data.song_name(song_id) for song_id in recommended_song_ids]\n",
    "\n",
    "userId = 'b7815dbb206eb2831ce0fe040d0aa537e2e800f7'\n",
    "print(\"Songs recommended for a user:\", recommend_songs(model, songs, userId, all_data, n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.evaluation import precision_at_k\n",
    "# Evaluate using p@k\n",
    "\n",
    "# implicit.evaluation.precision_at_k(model, train_user_items, test_user_items, int K=10, show_progress=True, int num_threads=1)\n",
    "p_at_k = precision_at_k(model, train_matrix, test_matrix, K=10, show_progress=True, num_threads=1)\n",
    "# average_precision = precision_at_k(model, test_matrix)\n",
    "# print(f\"Average Precision at k: {average_precision:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
